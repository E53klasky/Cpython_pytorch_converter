{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dd81db-b0be-47f3-a74b-5c210cb4361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f7f3b-9f00-484b-b212-a5408e0b1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd60687-acd4-4a8b-974d-a58c475a2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CAESAR.models.network_components import ResnetBlock, FlexiblePrior, Downsample, Upsample\n",
    "from CAESAR.models.utils import quantize, NormalDistribution\n",
    "import time\n",
    "import yaml\n",
    "from CAESAR.models.BCRN.bcrn_model import BluePrintConvNeXt_SR\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from CAESAR.models.RangeEncoding import RangeCoder\n",
    "\n",
    "\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data\n",
    "\n",
    "def super_resolution_model(img_size = 64, in_chans=32, out_chans=1, sr_dim = \"HAT\", pretrain = False, sr_type = \"BCRN\"):\n",
    "    \n",
    "    if sr_type == \"BCRN\":\n",
    "        sr_model = BluePrintConvNeXt_SR(in_chans, 1, 4, sr_dim)\n",
    "        if pretrain:\n",
    "            loaded_params, not_loaded_params = sr_model.load_part_model(\"./pretrain/BCRN_SRx4.pth\")\n",
    "        else:\n",
    "            loaded_params, not_loaded_params = [], sr_model.parameters()\n",
    "        \n",
    "        return sr_model, loaded_params, not_loaded_params\n",
    "\n",
    "def reshape_batch_2d_3d(batch_data, batch_size):\n",
    "    BT,C,H,W = batch_data.shape\n",
    "    T = BT//batch_size\n",
    "    batch_data = batch_data.view([batch_size, T, C, H, W])\n",
    "    batch_data = batch_data.permute([0,2,1,3,4])\n",
    "    return batch_data\n",
    "\n",
    "def reshape_batch_3d_2d(batch_data):\n",
    "    B,C,T,H,W = batch_data.shape\n",
    "    batch_data = batch_data.permute([0,2,1,3,4]).reshape([B*T,C,H,W])\n",
    "    return batch_data\n",
    "\n",
    "\n",
    "\n",
    "class Compressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 3, 4),\n",
    "        reverse_dim_mults=(4, 3, 2, 1),\n",
    "        hyper_dims_mults=(4, 4, 4),\n",
    "        channels=3,\n",
    "        out_channels=3,\n",
    "        d3 = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
    "        self.in_out = list(zip(self.dims[:-1], self.dims[1:]))\n",
    "        \n",
    "        self.reversed_dims = [*map(lambda m: dim * m, reverse_dim_mults), out_channels]\n",
    "        self.reversed_in_out = list(zip(self.reversed_dims[:-1], self.reversed_dims[1:]))\n",
    "        \n",
    "        assert self.dims[-1] == self.reversed_dims[0]\n",
    "        self.hyper_dims = [self.dims[-1], *map(lambda m: dim * m, hyper_dims_mults)]\n",
    "        self.hyper_in_out = list(zip(self.hyper_dims[:-1], self.hyper_dims[1:]))\n",
    "        self.reversed_hyper_dims = list(\n",
    "            reversed([self.dims[-1] * 2, *map(lambda m: dim * m, hyper_dims_mults)])\n",
    "        )\n",
    "        self.reversed_hyper_in_out = list(\n",
    "            zip(self.reversed_hyper_dims[:-1], self.reversed_hyper_dims[1:])\n",
    "        )\n",
    "        self.prior = FlexiblePrior(self.hyper_dims[-1], convert_module = True)\n",
    "        \n",
    "        self.range_coder = None\n",
    "\n",
    "    def get_extra_loss(self):\n",
    "        return self.prior.get_extraloss()\n",
    "\n",
    "    def build_network(self):\n",
    "        self.enc = nn.ModuleList([])\n",
    "        self.dec = nn.ModuleList([])\n",
    "        self.hyper_enc = nn.ModuleList([])\n",
    "        self.hyper_dec = nn.ModuleList([])\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        self.t_dim = x.shape[2]\n",
    "        \n",
    "        for i, (resnet, down) in enumerate(self.enc): # [b, 1, t, 256, 256]\n",
    "            if i==0:\n",
    "                x = x.permute(0,2,1,3,4)\n",
    "                x = x.reshape(-1, *x.shape[2:]) # [b*t, 1, 256, 256]\n",
    "            if i==2:\n",
    "                x = x.reshape(-1, self.t_dim, *x.shape[1:])\n",
    "                x = x.permute(0,2,1,3,4) # [b, c, t, h, w]\n",
    "                \n",
    "            x = resnet(x)\n",
    "            x = down(x)\n",
    "            \n",
    "\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        x = x.reshape(-1, *x.shape[2:])\n",
    "        \n",
    "        latent = x\n",
    "        return latent\n",
    "    \n",
    "        \n",
    "    \n",
    "    def hyper_encode(self, x):\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        for i, (conv, act) in enumerate(self.hyper_enc):\n",
    "            x = conv(x)\n",
    "            x = act(x)\n",
    "            \n",
    "        hyper_latent = x\n",
    "        return hyper_latent\n",
    "    \n",
    "    \n",
    "    def hyper_decode(self, x): \n",
    "        \n",
    "        for i, (deconv, act) in enumerate(self.hyper_dec):\n",
    "            x = deconv(x)\n",
    "            x = act(x)\n",
    "\n",
    "        mean, scale = x.chunk(2, 1)\n",
    "        \n",
    "        return mean, scale\n",
    "    \n",
    "    \n",
    "    def decode(self, x): # [n*t, c, h,w ] [8, 256, 16, 16]\n",
    "        # output = []\n",
    "        \n",
    "        for i, (resnet, up) in enumerate(self.dec):\n",
    "            \n",
    "            if i==0:\n",
    "                x = x.reshape(-1, self.t_dim//4, *x.shape[1:])\n",
    "                x = x.permute(0,2,1,3,4) # [b, c, t, h, w]\n",
    "                \n",
    "            if i==2:\n",
    "                x = x.permute(0,2,1,3,4)\n",
    "                x = x.reshape(-1, *x.shape[2:]) # [b*t, 1, 256, 256]\n",
    "                \n",
    "            x = resnet(x)\n",
    "            x = up(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def compress(self, x, return_latent = False, real = False, return_time = False):\n",
    "        if self.range_coder is None:\n",
    "            _quantized_cdf, _cdf_length, _offset = self.prior._update(30)\n",
    "            self.range_coder = RangeCoder(_quantized_cdf = _quantized_cdf, _cdf_length= _cdf_length, _offset= _offset, medians = self.prior.medians.detach())\n",
    "            \n",
    "        B,C,T,H,W = x.shape\n",
    "        original_shape = x.shape\n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            start_time = time.time()\n",
    "\n",
    "        latent = self.encode(x)\n",
    "        hyper_latent = self.hyper_encode(latent)\n",
    "        q_hyper_latent = quantize(hyper_latent, \"dequantize\", self.prior.medians)\n",
    "        mean, scale = self.hyper_decode(q_hyper_latent)\n",
    "        '''\n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            elapsed_time = time.time() - start_time\n",
    "        \n",
    "        latent_string = self.range_coder.compress(latent, mean, scale)\n",
    "        hyper_latent_string = self.range_coder.compress_hyperlatent(hyper_latent)\n",
    "        \n",
    "        bpf_real = torch.Tensor([(len(lc)+len(hc))*8 for lc, hc in zip(latent_string, hyper_latent_string)])\n",
    "        \n",
    "        compressed_data = (latent_string, hyper_latent_string, original_shape, hyper_latent.shape)\n",
    "\n",
    "        state4bpp = {\"latent\": latent, \"hyper_latent\": hyper_latent, \"mean\":mean, \"scale\": scale}\n",
    "        \n",
    "        bpf_theory, bpp = self.bpp(original_shape, state4bpp)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        result[\"bpf_entropy\"] = bpf_theory\n",
    "        result[\"compressed\"] = compressed_data\n",
    "        result[\"bpf_real\"] = bpf_real\n",
    "\n",
    "        \n",
    "        if return_latent:\n",
    "            q_latent = quantize(latent, \"dequantize\", mean)\n",
    "            result[\"q_latent\"] = q_latent\n",
    "            \n",
    "        if return_time:\n",
    "            result[\"elapsed_time\"] = elapsed_time\n",
    "        '''\n",
    "        #return latent_string, hyper_latent_string\n",
    "        return latent, hyper_latent\n",
    "    \n",
    "    def decompress(self, latent_string, hyper_latent_string, original_shape, hyper_shape, device = \"cuda\"):\n",
    "        B, _, T, _, _ = original_shape\n",
    "        q_hyper_latent = self.range_coder.decompress_hyperlatent(hyper_latent_string, hyper_shape)\n",
    "        mean, scale = self.hyper_decode(q_hyper_latent.to(device))\n",
    "        \n",
    "        q_latent = self.range_coder.decompress(latent_string, mean.detach().cpu(), scale.detach().cpu())\n",
    "        q_latent = q_latent.to(device)\n",
    "        \n",
    "        return self.decode(q_latent)\n",
    "    \n",
    "\n",
    "    def bpp(self, shape, state4bpp):\n",
    "        B, H, W = shape[0], shape[-2], shape[-1]\n",
    "        n_pixels = shape[-3] * shape[-2] * shape[-1]\n",
    "        \n",
    "        latent = state4bpp[\"latent\"]\n",
    "        hyper_latent = state4bpp[\"hyper_latent\"]\n",
    "        latent_distribution = NormalDistribution(state4bpp['mean'], state4bpp['scale'].clamp(min=0.1))\n",
    "        \n",
    "        if self.training:\n",
    "            q_hyper_latent = quantize(hyper_latent, \"noise\")\n",
    "            q_latent = quantize(latent, \"noise\")\n",
    "        else:\n",
    "            q_hyper_latent = quantize(hyper_latent, \"dequantize\", self.prior.medians)\n",
    "            q_latent = quantize(latent, \"dequantize\", latent_distribution.mean)\n",
    "            \n",
    "        hyper_rate = -self.prior.likelihood(q_hyper_latent).log2()\n",
    "        cond_rate = -latent_distribution.likelihood(q_latent).log2()\n",
    "        \n",
    "        bpb = hyper_rate.reshape(B, -1).sum(dim=-1) + cond_rate.reshape(B, -1).sum(dim=-1) # bit per block\n",
    "        bpp = (hyper_rate.reshape(B, -1).sum(dim=-1) + cond_rate.reshape(B, -1).sum(dim=-1)) / n_pixels\n",
    "        \n",
    "        return bpb, bpp\n",
    "\n",
    "    def forward(self, x, return_time = False):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            start_time = time.time()\n",
    "            \n",
    "        # q_latent, q_hyper_latent, state4bpp, mean = self.encode(x)\n",
    "        \n",
    "        \n",
    "        latent = self.encode(x)\n",
    "        hyper_latent = self.hyper_encode(latent) \n",
    "        q_hyper_latent = quantize(hyper_latent, \"dequantize\", self.prior.medians)\n",
    "        mean, scale = self.hyper_decode(q_hyper_latent)\n",
    "        q_latent = quantize(latent, \"dequantize\", mean.detach())\n",
    "        \n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            result[\"encoding_time\"] = time.time() - start_time\n",
    "            \n",
    "            \n",
    "            \n",
    "        state4bpp = {\"latent\": latent, \"hyper_latent\":hyper_latent, \"mean\":mean, \"scale\":scale }    \n",
    "        frame_bit, bpp = self.bpp(x.shape, state4bpp)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            start_time = time.time()\n",
    "            \n",
    "        output = self.decode(q_latent)\n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            result[\"decoding_time\"] = time.time() - start_time\n",
    "            \n",
    "        result.update({\n",
    "            \"output\": output,\n",
    "            \"bpp\": bpp,\n",
    "            \"frame_bit\":frame_bit,\n",
    "            \"mean\": mean,\n",
    "            \"q_latent\": q_latent,\n",
    "            \"q_hyper_latent\": q_hyper_latent,\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class ResnetCompressor(Compressor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 3, 4),\n",
    "        reverse_dim_mults=(4, 3, 2, 1),\n",
    "        hyper_dims_mults=(4, 4, 4),\n",
    "        channels=3,\n",
    "        out_channels=3,\n",
    "        d3 = False\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim,\n",
    "            dim_mults,\n",
    "            reverse_dim_mults,\n",
    "            hyper_dims_mults,\n",
    "            channels,\n",
    "            out_channels,\n",
    "            d3\n",
    "        )\n",
    "        self.d3 = d3\n",
    "        self.conv_layer =  nn.Conv3d if d3 else nn.Conv2d\n",
    "        self.deconv_layer = nn.ConvTranspose3d if d3 else nn.ConvTranspose2d\n",
    "        \n",
    "        self.build_network()\n",
    "        \n",
    "\n",
    "    def build_network(self):\n",
    "\n",
    "        self.enc = nn.ModuleList([])\n",
    "        self.dec = nn.ModuleList([])\n",
    "        self.hyper_enc = nn.ModuleList([])\n",
    "        self.hyper_dec = nn.ModuleList([])\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.in_out):\n",
    "            is_last = ind >= (len(self.in_out) - 1)\n",
    "            d3 = self.d3 if ind>=2 else False\n",
    "            self.enc.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_in, dim_out, None, True if ind == 0 else False, d3 = d3),\n",
    "                        Downsample(dim_out, d3 = d3),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.reversed_in_out):\n",
    "            is_last = ind >= (len(self.reversed_in_out) - 1)\n",
    "            d3 = self.d3 if ind<2 else False\n",
    "                \n",
    "            self.dec.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_in, dim_out if not is_last else dim_in, d3 = d3),\n",
    "                        Upsample(dim_out if not is_last else dim_in, dim_out, d3 = d3) if d3 else nn.Identity()\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.hyper_in_out):\n",
    "            is_last = ind >= (len(self.hyper_in_out) - 1)\n",
    "            self.hyper_enc.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Conv2d(dim_in, dim_out, 3, 1, 1) if ind == 0 else nn.Conv2d(dim_in, dim_out, 5, 2, 2),\n",
    "                        nn.LeakyReLU(0.2) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.reversed_hyper_in_out):\n",
    "            is_last = ind >= (len(self.reversed_hyper_in_out) - 1)\n",
    "            self.hyper_dec.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Conv2d(dim_in, dim_out, 3, 1, 1) if is_last else nn.ConvTranspose2d(dim_in, dim_out, 5, 2, 2, 1),\n",
    "                        nn.LeakyReLU(0.2) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "class CompressorMix(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 3, 4),\n",
    "        reverse_dim_mults=(4, 3, 2, 1),\n",
    "        hyper_dims_mults=(4, 4, 4),\n",
    "        channels=3,\n",
    "        out_channels=3,\n",
    "        d3=False,\n",
    "        sr_dim = 16\n",
    "    ):\n",
    "        super().__init__()  # Initialize the nn.Module parent class\n",
    "\n",
    "        self.entropy_model = ResnetCompressor(\n",
    "            dim,\n",
    "            dim_mults,\n",
    "            reverse_dim_mults,\n",
    "            hyper_dims_mults,\n",
    "            channels,\n",
    "            out_channels,\n",
    "            d3\n",
    "        )\n",
    "\n",
    "        # Update channels for sr_model based on entropy_model's output\n",
    "        channels = dim * reverse_dim_mults[-1]\n",
    "\n",
    "        # Initialize super-resolution model\n",
    "        self.sr_model, self.loaded_params, self.not_loaded_params = super_resolution_model(\n",
    "            img_size=64, in_chans=channels, out_chans=out_channels, sr_type = \"BCRN\", sr_dim = sr_dim\n",
    "        )\n",
    "    '''\n",
    "    def forward(self, x, return_time = False):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        results = self.entropy_model(x, return_time)\n",
    "        outputs = results[\"output\"]\n",
    "        \n",
    "        # Apply super-resolution model\n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            start_time = time.time()\n",
    "            \n",
    "        outputs = self.sr_model(outputs)  # Use self.sr_model instead of sr_model\n",
    "        \n",
    "        if return_time:\n",
    "            torch.cuda.synchronize()  # Wait for all GPU ops to finish\n",
    "            results[\"decoding_time\"] += time.time() - start_time\n",
    "            \n",
    "        \n",
    "        # Reshape if needed\n",
    "        outputs = reshape_batch_2d_3d(outputs, B)\n",
    "        results[\"output\"] = outputs\n",
    "        \n",
    "        return results\n",
    "    '''\n",
    "    def compress(self, x, return_latent = False,  real = False):\n",
    "        return self.entropy_model.compress(x, return_latent, real)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #dataset_org = dataloader.dataset\n",
    "        #self.transform_shape = dataset_org.deblocking_hw\n",
    "        \n",
    "        #compressed_latent, latent_bytes = self.compress_caesar_v(x)\n",
    "        latent, hyper_latent = self.compress(x)\n",
    "        #latent_bytes = torch.sum(outputs[\"bpf_real\"])                \n",
    "        #compressed_latent = outputs[\"compressed\"]\n",
    "  \n",
    "        #original_data = dataset_org.original_data()\n",
    "        #print(\"original_data.shape after compress\", original_data.shape, recons_data.shape)\n",
    "        #original_data, org_padding = self.padding(original_data)\n",
    "        #recons_data, rec_padding= self.padding(recons_data)\n",
    "        \n",
    "        #meta_data, compressed_gae = self.postprocessing_encoding(original_data, recons_data, eb)\n",
    "        return latent, hyper_latent\n",
    "    \n",
    "    '''\n",
    "    def compress_caesar_v(self, dataloader):\n",
    "\n",
    "        total_bits = 0\n",
    "        all_compressed_latent = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                outputs = self.compress(data[0].to('cuda'))\n",
    "                total_bits += torch.sum(outputs[\"bpf_real\"])\n",
    "                \n",
    "                compressed_latent = outputs[\"compressed\"]\n",
    "                all_compressed_latent.append(compressed_latent)\n",
    "                \n",
    "        return all_compressed_latent, total_bits/8\n",
    "    '''\n",
    "    \n",
    "    def decompress(self, latent_string, hyper_latent_string, original_shape, hyper_shape, device = \"cuda\"):\n",
    "        B = original_shape[0]\n",
    "        \n",
    "        outputs = self.entropy_model.decompress(latent_string, hyper_latent_string, original_shape, hyper_shape, device)\n",
    "        outputs = self.sr_model(outputs)\n",
    "        \n",
    "        outputs = reshape_batch_2d_3d(outputs, B)\n",
    "        return outputs\n",
    "    \n",
    "    def decode(self, x, batch_size):\n",
    "        x = self.entropy_model.decode(x)\n",
    "        x = self.sr_model(x)\n",
    "        x = reshape_batch_2d_3d(x, batch_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc919371-4ea6-45af-aabd-19b032015366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def remove_module_prefix(state_dict):\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")\n",
    "            new_state_dict[new_key] = v\n",
    "        return new_state_dict\n",
    "    \n",
    "model = CompressorMix(\n",
    "            dim=16,\n",
    "            dim_mults=[1, 2, 3, 4],\n",
    "            reverse_dim_mults=[4, 3, 2],\n",
    "            hyper_dims_mults=[4, 4, 4],\n",
    "            channels=1,\n",
    "            out_channels=1,\n",
    "            d3=True,\n",
    "            sr_dim=16\n",
    "        )\n",
    "\n",
    "state_dict = remove_module_prefix(torch.load('./pretrained/caesar_v.pt', map_location='cuda'))\n",
    "#state_dict = torch.load('./pretrained/caesar_v.pt', map_location='cuda')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b93a4fad-1ed2-4fd1-9c9d-41f290a5d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 15:13:51.039000 1165267 site-packages/torch/fx/experimental/symbolic_shapes.py:6646] [3/0] runtime_asserts_frozen but then got 8388608*s0 < 2147483648\n",
      "/usr/bin/ld: warning: /tmp/torchinductor_jlx/c3x2wzvybtykln46jzyqk6b2n6rmj3fduanohtgzl6mxrl6c3g7t/cphqhfrh733iitmsfvhs6fw22qdbnjjfo65b7rg4jzzi7pvn76a7/cwv3anxflj7rgjzquetizmu5o6br4a4uoe327utlxwgh7byv3334.o: missing .note.GNU-stack section implies executable stack\n",
      "/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('device: ', device)\n",
    "    model = model.to(device)\n",
    "    example_inputs=(torch.randn(8, 1, 8, 256, 256, device=device),)\n",
    "    batch_dim = torch.export.Dim(\"batch\", min=1, max=1024)\n",
    "    # [Optional] Specify the first dimension of the input x as dynamic.\n",
    "    exported = torch.export.export(model, example_inputs, dynamic_shapes={\"x\": {0: batch_dim}})\n",
    "    # [Note] In this example we directly feed the exported module to aoti_compile_and_package.\n",
    "    # Depending on your use case, e.g. if your training platform and inference platform\n",
    "    # are different, you may choose to save the exported model using torch.export.save and\n",
    "    # then load it back using torch.export.load on your inference platform to run AOT compilation.\n",
    "    output_path = torch._inductor.aoti_compile_and_package(\n",
    "        exported,\n",
    "        # [Optional] Specify the generated shared library path. If not specified,\n",
    "        # the generated artifact is stored in your system temp directory.\n",
    "        package_path=os.path.join(os.getcwd(), \"model.pt2\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696a55e-6587-4811-84ed-3dea5f17abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
